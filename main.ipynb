{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import bibtexparser\n",
    "from eldar import Query\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/573/rh2942/boolean-search-bib-abstract\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('anthology+abstracts.bib') as bib_file:\n",
    "    bib_database = bibtexparser.load(bib_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns= ['title', 'abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of items: 46079\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of items: {len(bib_database.entries)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, bibitem in enumerate(bib_database.entries):\n",
    "    title = bibitem.get('title')\n",
    "    abstract = bibitem.get('abstract')\n",
    "\n",
    "    # KeyError if title/abstract doesn't exist on a bibitem, so if/else used to handle\n",
    "    df.loc[index, 'title'] = title if title else \"\"\n",
    "    df.loc[index, 'abstract'] = abstract if abstract else \"\"\n",
    "\n",
    "\n",
    "# combine title and abstract to search\n",
    "df['title-abstract'] = df['title'] + df['abstract']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>title-abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10026</th>\n",
       "      <td>Team {UDEL} {KBG}en 2013 Challenge</td>\n",
       "      <td></td>\n",
       "      <td>Team {UDEL} {KBG}en 2013 Challenge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46052</th>\n",
       "      <td>Mechanical Translation of {F}rench</td>\n",
       "      <td></td>\n",
       "      <td>Mechanical Translation of {F}rench</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11239</th>\n",
       "      <td>Coherence Modeling for the Automated Assessmen...</td>\n",
       "      <td></td>\n",
       "      <td>Coherence Modeling for the Automated Assessmen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title abstract  \\\n",
       "10026                 Team {UDEL} {KBG}en 2013 Challenge            \n",
       "46052                 Mechanical Translation of {F}rench            \n",
       "11239  Coherence Modeling for the Automated Assessmen...            \n",
       "\n",
       "                                          title-abstract  \n",
       "10026                 Team {UDEL} {KBG}en 2013 Challenge  \n",
       "46052                 Mechanical Translation of {F}rench  \n",
       "11239  Coherence Modeling for the Automated Assessmen...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Article-title-ACL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/kerighan/eldar\n",
    "\n",
    "# eldar = Query('empath* AND (detect* OR recog* OR predict*) AND (\"deep learning\" OR \"machine learning\" OR \"artificial intelligence\" OR AI)', ignore_case=True, ignore_accent=True, match_word=False)\n",
    "eldar = Query('empath* AND (detect* OR recog* OR predict*)', ignore_case=True, ignore_accent=True, match_word=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = df[df['title-abstract'].apply(eldar)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>title-abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>Global-Local Modeling with Prompt-Based Knowle...</td>\n",
       "      <td>The ability to recognize emotions in conversat...</td>\n",
       "      <td>Global-Local Modeling with Prompt-Based Knowle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>{WASSA} 2022 Shared Task: Predicting Empathy, ...</td>\n",
       "      <td>This paper presents the results that were obta...</td>\n",
       "      <td>{WASSA} 2022 Shared Task: Predicting Empathy, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>{IUCL} at {WASSA} 2022 Shared Task: A Text-onl...</td>\n",
       "      <td>Our system, IUCL, participated in the WASSA 20...</td>\n",
       "      <td>{IUCL} at {WASSA} 2022 Shared Task: A Text-onl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1009</th>\n",
       "      <td>Continuing Pre-trained Model with Multiple Tra...</td>\n",
       "      <td>Emotion is the essential attribute of human be...</td>\n",
       "      <td>Continuing Pre-trained Model with Multiple Tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>Empathy and Distress Prediction using Transfor...</td>\n",
       "      <td>This paper describes the participation of the ...</td>\n",
       "      <td>Empathy and Distress Prediction using Transfor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>Team {IITP}-{AINLPML} at {WASSA} 2022: Empathy...</td>\n",
       "      <td>Computational comprehension and identifying em...</td>\n",
       "      <td>Team {IITP}-{AINLPML} at {WASSA} 2022: Empathy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>Transformer-based Architecture for Empathy Pre...</td>\n",
       "      <td>This paper describes the contribution of team ...</td>\n",
       "      <td>Transformer-based Architecture for Empathy Pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>{SURREY}-{CTS}-{NLP} at {WASSA}2022: An Experi...</td>\n",
       "      <td>This paper summarises the submissions our team...</td>\n",
       "      <td>{SURREY}-{CTS}-{NLP} at {WASSA}2022: An Experi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>An Ensemble Approach to Detect Emotions at an ...</td>\n",
       "      <td>This paper describes our system (IREL, reffere...</td>\n",
       "      <td>An Ensemble Approach to Detect Emotions at an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>{CAISA} at {WASSA} 2022: Adapter-Tuning for Em...</td>\n",
       "      <td>We build a system that leverages adapters, a l...</td>\n",
       "      <td>{CAISA} at {WASSA} 2022: Adapter-Tuning for Em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2266</th>\n",
       "      <td>Linguistic Elements of Engaging Customer Servi...</td>\n",
       "      <td>Customers are rapidly turning to social media ...</td>\n",
       "      <td>Linguistic Elements of Engaging Customer Servi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2483</th>\n",
       "      <td>Empathic Machines: Using Intermediate Features...</td>\n",
       "      <td>We present a method to control the emotional p...</td>\n",
       "      <td>Empathic Machines: Using Intermediate Features...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2760</th>\n",
       "      <td>Emp-{RFT}: Empathetic Response Generation via ...</td>\n",
       "      <td>Each utterance in multi-turn empathetic dialog...</td>\n",
       "      <td>Emp-{RFT}: Empathetic Response Generation via ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>bitsa{\\_}nlp@{LT}-{EDI}-{ACL}2022: Leveraging ...</td>\n",
       "      <td>Online social networks are ubiquitous and user...</td>\n",
       "      <td>bitsa{\\_}nlp@{LT}-{EDI}-{ACL}2022: Leveraging ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3854</th>\n",
       "      <td>{MMDAG}: Multimodal Directed Acyclic Graph Net...</td>\n",
       "      <td>Emotion recognition in conversation is importa...</td>\n",
       "      <td>{MMDAG}: Multimodal Directed Acyclic Graph Net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4332</th>\n",
       "      <td>{IAE}mp: Intent-aware Empathetic Response Gene...</td>\n",
       "      <td>In the domain of virtual assistants or convers...</td>\n",
       "      <td>{IAE}mp: Intent-aware Empathetic Response Gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5174</th>\n",
       "      <td>Empathetic Dialogue Generation via Sensitive E...</td>\n",
       "      <td>Empathy, which is widely used in psychological...</td>\n",
       "      <td>Empathetic Dialogue Generation via Sensitive E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5990</th>\n",
       "      <td>D4: a {C}hinese Dialogue Dataset for Depressio...</td>\n",
       "      <td>In a depression-diagnosis-directed clinical se...</td>\n",
       "      <td>D4: a {C}hinese Dialogue Dataset for Depressio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6463</th>\n",
       "      <td>Calibrating Student Models for Emotion-related...</td>\n",
       "      <td>Knowledge Distillation (KD) is an effective me...</td>\n",
       "      <td>Calibrating Student Models for Emotion-related...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8010</th>\n",
       "      <td>Using Extracted Emotion Cause to Improve Conte...</td>\n",
       "      <td>{``}Empathetic conversation generation intends...</td>\n",
       "      <td>Using Extracted Emotion Cause to Improve Conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8058</th>\n",
       "      <td>Extended Multilingual Protest News Detection -...</td>\n",
       "      <td>We report results of the CASE 2022 Shared Task...</td>\n",
       "      <td>Extended Multilingual Protest News Detection -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14034</th>\n",
       "      <td>Building a Multimodal Laughter Database for Em...</td>\n",
       "      <td>Laughter is a significant paralinguistic cue t...</td>\n",
       "      <td>Building a Multimodal Laughter Database for Em...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "306    Global-Local Modeling with Prompt-Based Knowle...   \n",
       "1007   {WASSA} 2022 Shared Task: Predicting Empathy, ...   \n",
       "1008   {IUCL} at {WASSA} 2022 Shared Task: A Text-onl...   \n",
       "1009   Continuing Pre-trained Model with Multiple Tra...   \n",
       "1010   Empathy and Distress Prediction using Transfor...   \n",
       "1013   Team {IITP}-{AINLPML} at {WASSA} 2022: Empathy...   \n",
       "1014   Transformer-based Architecture for Empathy Pre...   \n",
       "1016   {SURREY}-{CTS}-{NLP} at {WASSA}2022: An Experi...   \n",
       "1017   An Ensemble Approach to Detect Emotions at an ...   \n",
       "1018   {CAISA} at {WASSA} 2022: Adapter-Tuning for Em...   \n",
       "2266   Linguistic Elements of Engaging Customer Servi...   \n",
       "2483   Empathic Machines: Using Intermediate Features...   \n",
       "2760   Emp-{RFT}: Empathetic Response Generation via ...   \n",
       "3048   bitsa{\\_}nlp@{LT}-{EDI}-{ACL}2022: Leveraging ...   \n",
       "3854   {MMDAG}: Multimodal Directed Acyclic Graph Net...   \n",
       "4332   {IAE}mp: Intent-aware Empathetic Response Gene...   \n",
       "5174   Empathetic Dialogue Generation via Sensitive E...   \n",
       "5990   D4: a {C}hinese Dialogue Dataset for Depressio...   \n",
       "6463   Calibrating Student Models for Emotion-related...   \n",
       "8010   Using Extracted Emotion Cause to Improve Conte...   \n",
       "8058   Extended Multilingual Protest News Detection -...   \n",
       "14034  Building a Multimodal Laughter Database for Em...   \n",
       "\n",
       "                                                abstract  \\\n",
       "306    The ability to recognize emotions in conversat...   \n",
       "1007   This paper presents the results that were obta...   \n",
       "1008   Our system, IUCL, participated in the WASSA 20...   \n",
       "1009   Emotion is the essential attribute of human be...   \n",
       "1010   This paper describes the participation of the ...   \n",
       "1013   Computational comprehension and identifying em...   \n",
       "1014   This paper describes the contribution of team ...   \n",
       "1016   This paper summarises the submissions our team...   \n",
       "1017   This paper describes our system (IREL, reffere...   \n",
       "1018   We build a system that leverages adapters, a l...   \n",
       "2266   Customers are rapidly turning to social media ...   \n",
       "2483   We present a method to control the emotional p...   \n",
       "2760   Each utterance in multi-turn empathetic dialog...   \n",
       "3048   Online social networks are ubiquitous and user...   \n",
       "3854   Emotion recognition in conversation is importa...   \n",
       "4332   In the domain of virtual assistants or convers...   \n",
       "5174   Empathy, which is widely used in psychological...   \n",
       "5990   In a depression-diagnosis-directed clinical se...   \n",
       "6463   Knowledge Distillation (KD) is an effective me...   \n",
       "8010   {``}Empathetic conversation generation intends...   \n",
       "8058   We report results of the CASE 2022 Shared Task...   \n",
       "14034  Laughter is a significant paralinguistic cue t...   \n",
       "\n",
       "                                          title-abstract  \n",
       "306    Global-Local Modeling with Prompt-Based Knowle...  \n",
       "1007   {WASSA} 2022 Shared Task: Predicting Empathy, ...  \n",
       "1008   {IUCL} at {WASSA} 2022 Shared Task: A Text-onl...  \n",
       "1009   Continuing Pre-trained Model with Multiple Tra...  \n",
       "1010   Empathy and Distress Prediction using Transfor...  \n",
       "1013   Team {IITP}-{AINLPML} at {WASSA} 2022: Empathy...  \n",
       "1014   Transformer-based Architecture for Empathy Pre...  \n",
       "1016   {SURREY}-{CTS}-{NLP} at {WASSA}2022: An Experi...  \n",
       "1017   An Ensemble Approach to Detect Emotions at an ...  \n",
       "1018   {CAISA} at {WASSA} 2022: Adapter-Tuning for Em...  \n",
       "2266   Linguistic Elements of Engaging Customer Servi...  \n",
       "2483   Empathic Machines: Using Intermediate Features...  \n",
       "2760   Emp-{RFT}: Empathetic Response Generation via ...  \n",
       "3048   bitsa{\\_}nlp@{LT}-{EDI}-{ACL}2022: Leveraging ...  \n",
       "3854   {MMDAG}: Multimodal Directed Acyclic Graph Net...  \n",
       "4332   {IAE}mp: Intent-aware Empathetic Response Gene...  \n",
       "5174   Empathetic Dialogue Generation via Sensitive E...  \n",
       "5990   D4: a {C}hinese Dialogue Dataset for Depressio...  \n",
       "6463   Calibrating Student Models for Emotion-related...  \n",
       "8010   Using Extracted Emotion Cause to Improve Conte...  \n",
       "8058   Extended Multilingual Protest News Detection -...  \n",
       "14034  Building a Multimodal Laughter Database for Em...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv(\"Resulted match-ACL.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
